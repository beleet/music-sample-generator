{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicLM model\n",
    "### Robert Chen, Ahmadsho Akdodshoev, Philip Timofeev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, distributed as dist\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import einops\n",
    "from einops.layers.torch import Rearrange\n",
    "import math\n",
    "from functools import wraps, partial\n",
    "from torchaudio import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_dim_to(t, length, dim = 0):\n",
    "    pad_length = length - t.shape[dim]\n",
    "    zero_pairs = (-dim - 1) if dim < 0 else (t.ndim - dim - 1)\n",
    "    return F.pad(t, (*((0, 0) * zero_pairs), 0, pad_length))\n",
    "    \n",
    "def _all_gather(tensor):\n",
    "    world_size = dist.get_world_size()\n",
    "    gathered = [torch.empty_like(tensor, device=tensor.device, dtype=tensor.dtype) for i in range(world_size)]\n",
    "    dist.all_gather(gathered, tensor)\n",
    "    return gathered\n",
    "\n",
    "def all_gather(tensor, dim=0, sizes=None):\n",
    "    device, rank, world_size = tensor.device, dist.get_rank(), dist.get_world_size()\n",
    "    \n",
    "    if sizes is None:\n",
    "        size = torch.tensor(tensor.shape[dim], device=device, dtype=torch.long)\n",
    "        sizes = _all_gather(size)\n",
    "        sizes = torch.stack(sizes)\n",
    "        \n",
    "    if torch.unique(sizes).numel() == 1:\n",
    "        return torch.cat(_all_gather(tensor), dim=dim), sizes\n",
    "    \n",
    "    pad_size = sizes.amax().item()\n",
    "    padded_tensor = pad_dim_to(tensor, pad_size, dim=dim)\n",
    "    \n",
    "    sequence = torch.arange(pad_size, device=device)\n",
    "    mask = einops.rearrange(einops.rearrange(sequence, 'j -> 1 j') < einops.rearrange(sizes, 'i -> i 1'), 'i j -> (i j)')\n",
    "    \n",
    "    sequence = torch.arange(mask.shape[-1], device=device)\n",
    "    idx = sequence[mask]\n",
    "    \n",
    "    gathered = torch.cat(_all_gather(padded_tensor), dim=dim).index_select(dim, idx)\n",
    "    \n",
    "    return gathered, sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllGatherFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, dim, sizes, grads):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grads, _):\n",
    "        pass\n",
    "    \n",
    "class AllGather(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
