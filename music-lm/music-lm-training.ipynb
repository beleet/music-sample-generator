{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MusicLM model\n",
    "### Robert Chen, Ahmadsho Akdodshoev, Philip Timofeev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "from musiclm_pytorch import (\n",
    "    MuLaN, MuLaNEmbedQuantizer, MuLaNTrainer, \n",
    "    AudioSpectrogramTransformer, TextTransformer,\n",
    "    MusicLM\n",
    ")\n",
    "from audiolm_pytorch import (\n",
    "    SemanticTransformer, SemanticTransformerTrainer, \n",
    "    CoarseTransformer, CoarseTransformerTrainer, \n",
    "    FineTransformer, FineTransformerTrainer, \n",
    "    AudioLM, HubertWithKmeans, MusicLMSoundStream,\n",
    "    SoundStreamTrainer, SoundStream\n",
    ")\n",
    "import os\n",
    "import wave\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating dataloaders and downloading Hubert K-means checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLMDataset(Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        super().__init__()\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        ...\n",
    "\n",
    "\n",
    "train_dataset = MusicLMDataset('path/to/files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Hubert checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert_ckpt = './hubert/hubert_base_ls960.pt'\n",
    "hubert_quantizer = './hubert/hubert_base_ls960_L9_km500.bin'\n",
    "soundstream_ckpt = './results/soundstream.pt'\n",
    "\n",
    "if not os.path.isdir(\"hubert\"):\n",
    "  os.makedirs(\"hubert\")\n",
    "if not os.path.isfile(hubert_ckpt):\n",
    "  hubert_ckpt_download = f\"https://dl.fbaipublicfiles.com/{hubert_ckpt}\"\n",
    "  urllib.request.urlretrieve(hubert_ckpt_download, f\"./{hubert_ckpt}\")\n",
    "if not os.path.isfile(hubert_quantizer):\n",
    "  hubert_quantizer_download = f\"https://dl.fbaipublicfiles.com/{hubert_quantizer}\"\n",
    "  urllib.request.urlretrieve(hubert_quantizer_download, f\"./{hubert_quantizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training MuLaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments for every module are defined in the respective dictionaries to make fine-tuning easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m AUDIO_KWARGS \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdim\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m512\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdepth\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mspec_aug_stretch_factor\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.8\u001b[39m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m TEXT_KWARGS \u001b[39m=\u001b[39m {\n\u001b[0;32m---> 12\u001b[0m     dim: \u001b[39m512\u001b[39m,\n\u001b[1;32m     13\u001b[0m     depth: \u001b[39m6\u001b[39m,\n\u001b[1;32m     14\u001b[0m     heads: \u001b[39m8\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdim_head\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m64\u001b[39m\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m audio_transformer \u001b[39m=\u001b[39m AudioSpectrogramTransformer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mAUDIO_KWARGS)\n\u001b[1;32m     20\u001b[0m text_transformer \u001b[39m=\u001b[39m TextTransformer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mTEXT_KWARGS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dim' is not defined"
     ]
    }
   ],
   "source": [
    "AUDIO_KWARGS = {\n",
    "    'dim': 512,\n",
    "    'depth': 6,\n",
    "    'heads': 8,\n",
    "    'dim_head': 64,\n",
    "    'spec_n_fft': 128,\n",
    "    'spec_win_length': 24,\n",
    "    'spec_aug_stretch_factor': 0.8\n",
    "}\n",
    "\n",
    "TEXT_KWARGS = {\n",
    "    'dim': 512,\n",
    "    'depth': 6,\n",
    "    'heads': 8,\n",
    "    'dim_head': 64\n",
    "}\n",
    "\n",
    "MULAN_KWARGS = {\n",
    "    'num_train_steps': 10,\n",
    "    'batch_size': 4,\n",
    "    'force_clear_prev_results': True,\n",
    "    'save_model_every': 5\n",
    "}\n",
    "\n",
    "MULAN_QUANTIZER_KWARGS = {\n",
    "    'conditioning_dims': (1024, 1024, 1024),\n",
    "    'namespaces': ('semantic', 'coarse', 'fine')\n",
    "}\n",
    "\n",
    "HUBERT_KWARGS = {\n",
    "    'checkpoint_path': hubert_ckpt,\n",
    "    'kmeans_path': hubert_quantizer\n",
    "}\n",
    "\n",
    "SOUNDSTREAM_KWARGS = {\n",
    "    \n",
    "}\n",
    "\n",
    "SOUNDSTREAM_TRAINER_KWARGS = {\n",
    "    \n",
    "}\n",
    "    \n",
    "SEMANTIC_KWARGS = {\n",
    "    \n",
    "}\n",
    "\n",
    "COARSE_KWARGS = {\n",
    "    \n",
    "}\n",
    "\n",
    "FINE_KWARGS = {\n",
    "    \n",
    "}\n",
    "\n",
    "TRANSFORMER_TRAINER_KWARGS = {\n",
    "    'dataset': train_dataset,\n",
    "    \n",
    "}\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training MuLaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_transformer = AudioSpectrogramTransformer(**AUDIO_KWARGS)\n",
    "\n",
    "text_transformer = TextTransformer(**TEXT_KWARGS)\n",
    "\n",
    "mulan = MuLaN(audio_transformer, text_transformer)\n",
    "\n",
    "mulan_trainer = MuLaNTrainer(mulan, train_dataset, **MULAN_KWARGS)\n",
    "\n",
    "mulan_trainer.train()\n",
    "\n",
    "mulan_trainer.save('./models/MuLaN.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training SoundStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundstream = MusicLMSoundStream()\n",
    "soundstream_trainer = SoundStreamTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training conditioning embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the MuLaN Embed Quantizer and Hubert K-means Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = MuLaNEmbedQuantizer(\n",
    "    mulan=mulan,                         \n",
    "    **MULAN_QUANTIZER_KWARGS\n",
    ")\n",
    "\n",
    "wav2vec = HubertWithKmeans(\n",
    "    **HUBERT_KWARGS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Semantic Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundstream = MusicLMSoundStream()\n",
    "\n",
    "soundstream.load(soundstream_ckpt)\n",
    "\n",
    "semantic_transformer = SemanticTransformer(\n",
    "   num_semantic_tokens=wav2vec.codebook_size,\n",
    "   **SEMANTIC_KWARGS \n",
    ").to(DEVICE)\n",
    "\n",
    "semantic_trainer = SemanticTransformerTrainer(\n",
    "    wav2vec,\n",
    "    semantic_transformer,\n",
    "    audio_conditioner=quantizer,\n",
    "    **TRANSFORMER_TRAINER_KWARGS\n",
    ")\n",
    "\n",
    "semantic_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Coarse Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundstream = MusicLMSoundStream()\n",
    "\n",
    "soundstream.load(soundstream_ckpt)\n",
    "\n",
    "coarse_transformer = CoarseTransformer(\n",
    "    num_semantic_tokens=wav2vec.codebook_size,\n",
    "    **COARSE_KWARGS\n",
    ").to(DEVICE)\n",
    "\n",
    "coarse_trainer = CoarseTransformerTrainer(\n",
    "    wav2vec,\n",
    "    semantic_transformer,\n",
    "    codec=soundstream,\n",
    "    audio_conditioner=quantizer,\n",
    "    **TRANSFORMER_TRAINER_KWARGS\n",
    ")\n",
    "\n",
    "coarse_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Fine Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundstream = MusicLMSoundStream()\n",
    "\n",
    "soundstream.load(soundstream_ckpt)\n",
    "\n",
    "fine_transformer = FineTransformer(\n",
    "    codebook_size=wav2vec.codebook_size,\n",
    "    **FINE_KWARGS\n",
    ").to(DEVICE)\n",
    "\n",
    "fine_trainer = FineTransformerTrainer(\n",
    "    wav2vec,\n",
    "    semantic_transformer,\n",
    "    codec=soundstream\n",
    "    audio_conditioner=quantizer,\n",
    "    **TRANSFORMER_TRAINER_KWARGS\n",
    ")\n",
    "\n",
    "fine_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combining AudioLM and MusicLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_lm = AudioLM(\n",
    "    wav2vec=wav2vec,\n",
    "    codec=soundstream,\n",
    "    semantic_transformer=semantic_transformer,\n",
    "    coarse_transformer=coarse_transformer,\n",
    "    fine_transformer=fine_transformer   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_lm = MusicLM(\n",
    "    audio_lm=audio_lm,\n",
    "    mulan_embed_quantizer=quantizer\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
