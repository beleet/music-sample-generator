{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training MusicLM model\n### Robert Chen, Ahmadsho Akdodshoev, Philip Timofeev","metadata":{}},{"cell_type":"markdown","source":"## 0. Imports","metadata":{}},{"cell_type":"code","source":"# !pip install musiclm-pytorch\n!python --version","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:08:14.632699Z","iopub.execute_input":"2023-10-27T14:08:14.636061Z","iopub.status.idle":"2023-10-27T14:08:15.785505Z","shell.execute_reply.started":"2023-10-27T14:08:14.635956Z","shell.execute_reply":"2023-10-27T14:08:15.783973Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Python 3.10.12\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchaudio\nfrom musiclm_pytorch import MuLaN, MuLaNEmbedQuantizer, MuLaNTrainer, \\\n                            AudioSpectrogramTransformer, TextTransformer, MusicLM\nfrom audiolm_pytorch import SemanticTransformer, SemanticTransformerTrainer, \\\n                            CoarseTransformer, CoarseTransformerTrainer, \\\n                            FineTransformer, FineTransformerTrainer, \\\n                            AudioLM, HubertWithKmeans, MusicLMSoundStream, \\\n                            SoundStreamTrainer, SoundStream \nimport os\nimport wave\nimport urllib.request","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:06.914446Z","iopub.execute_input":"2023-10-27T14:05:06.915290Z","iopub.status.idle":"2023-10-27T14:05:06.930171Z","shell.execute_reply.started":"2023-10-27T14:05:06.915243Z","shell.execute_reply":"2023-10-27T14:05:06.928627Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 1. Creating dataloaders and downloading Hubert K-means checkpoints","metadata":{}},{"cell_type":"markdown","source":"Creating the dataset","metadata":{}},{"cell_type":"code","source":"dataset_path = './data/'","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:06.931806Z","iopub.execute_input":"2023-10-27T14:05:06.932232Z","iopub.status.idle":"2023-10-27T14:05:06.949779Z","shell.execute_reply.started":"2023-10-27T14:05:06.932199Z","shell.execute_reply":"2023-10-27T14:05:06.948326Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Downloading Hubert checkpoints","metadata":{}},{"cell_type":"code","source":"hubert_ckpt = 'hubert/hubert_base_ls960.pt'\nhubert_quantizer = 'hubert/hubert_base_ls960_L9_km500.bin'\nsoundstream_ckpt = './results/soundstream.pt'\n\nif not os.path.isdir(\"hubert\"):\n  os.makedirs(\"hubert\")\nif not os.path.isfile(hubert_ckpt):\n  hubert_ckpt_download = f\"https://dl.fbaipublicfiles.com/{hubert_ckpt}\"\n  urllib.request.urlretrieve(hubert_ckpt_download, f\"./{hubert_ckpt}\")\nif not os.path.isfile(hubert_quantizer):\n  hubert_quantizer_download = f\"https://dl.fbaipublicfiles.com/{hubert_quantizer}\"\n  urllib.request.urlretrieve(hubert_quantizer_download, f\"./{hubert_quantizer}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:06.952857Z","iopub.execute_input":"2023-10-27T14:05:06.953519Z","iopub.status.idle":"2023-10-27T14:05:12.146848Z","shell.execute_reply.started":"2023-10-27T14:05:06.953484Z","shell.execute_reply":"2023-10-27T14:05:12.145277Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 2. Training MuLaN","metadata":{}},{"cell_type":"markdown","source":"Arguments for every module are defined in the respective dictionaries to make fine-tuning easier","metadata":{}},{"cell_type":"code","source":"AUDIO_KWARGS = {\n    'dim': 512,\n    'depth': 6,\n    'heads': 8,\n    'dim_head': 64,\n    'spec_n_fft': 128,\n    'spec_win_length': 24,\n    'spec_aug_stretch_factor': 0.8\n}\n\nTEXT_KWARGS = {\n    'dim': 512,\n    'depth': 6,\n    'heads': 8,\n    'dim_head': 64\n}\n\nMULAN_KWARGS = {\n    'folder': dataset_path,\n    'num_train_steps': 10,\n    'batch_size': 4,\n    'force_clear_prev_results': True,\n    'save_model_every': 5\n}\n\nMULAN_QUANTIZER_KWARGS = {\n    'conditioning_dims': (1024, 1024, 1024),\n    'namespaces': ('semantic', 'coarse', 'fine')\n}\n\nHUBERT_KWARGS = {\n    'checkpoint_path': hubert_ckpt,\n    'kmeans_path': hubert_quantizer\n}\n\nSOUNDSTREAM_TRAINER_KWARGS = {\n    'folder': dataset_path,\n    'num_train_steps': 20,\n    'save_model_every': 2,\n    'batch_size': 4\n}\n    \nSEMANTIC_KWARGS = {\n    'dim':1024,\n    'depth': 6,\n    'audio_text_condition': True \n}\n\nCOARSE_KWARGS = {\n    'codebook_size': 1024,\n    'num_coarse_quantizers': 4,\n    'dim': 1024,\n    'depth': 6,\n    'audio_text_condition': True \n}\n\nFINE_KWARGS = {\n    'codebook_size': 1024,\n    'num_coarse_quantizers': 4,\n    'num_fine_quantizers': 8,\n    'dim': 1024,\n    'depth': 6,\n    'audio_text_condition': True \n}\n\nTRANSFORMER_TRAINER_KWARGS = {\n    'folder': dataset_path,\n    'num_train_steps': 10,\n    'save_model_every': 2,\n    'batch_size': 4,\n    'data_max_length': 320 * 32\n}\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:12.148988Z","iopub.execute_input":"2023-10-27T14:05:12.149410Z","iopub.status.idle":"2023-10-27T14:05:12.162459Z","shell.execute_reply.started":"2023-10-27T14:05:12.149378Z","shell.execute_reply":"2023-10-27T14:05:12.161104Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Training MuLaN","metadata":{}},{"cell_type":"code","source":"audio_transformer = AudioSpectrogramTransformer(**AUDIO_KWARGS)\n\ntext_transformer = TextTransformer(**TEXT_KWARGS)\n\nmulan = MuLaN(audio_transformer, text_transformer)\n\nmulan_trainer = MuLaNTrainer(mulan, **MULAN_KWARGS)\n\nmulan_trainer.train()\n\nmulan_trainer.save()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:12.164315Z","iopub.execute_input":"2023-10-27T14:05:12.164831Z","iopub.status.idle":"2023-10-27T14:05:13.256934Z","shell.execute_reply.started":"2023-10-27T14:05:12.164794Z","shell.execute_reply":"2023-10-27T14:05:13.254474Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m text_transformer \u001b[38;5;241m=\u001b[39m TextTransformer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mTEXT_KWARGS)\n\u001b[1;32m      5\u001b[0m mulan \u001b[38;5;241m=\u001b[39m MuLaN(audio_transformer, text_transformer)\n\u001b[0;32m----> 7\u001b[0m mulan_trainer \u001b[38;5;241m=\u001b[39m \u001b[43mMuLaNTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mMULAN_KWARGS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m mulan_trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     11\u001b[0m mulan_trainer\u001b[38;5;241m.\u001b[39msave()\n","File \u001b[0;32m<@beartype(musiclm_pytorch.trainer.MuLaNTrainer.__init__) at 0x7edb2a2272e0>:68\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(__beartype_func, __beartype_conf, __beartype_get_violation, __beartype_object_98562928107232, __beartype_object_98562805759184, *args, **kwargs)\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: MuLaNTrainer.__init__() missing 1 required positional argument: 'dataset'"],"ename":"TypeError","evalue":"MuLaNTrainer.__init__() missing 1 required positional argument: 'dataset'","output_type":"error"}]},{"cell_type":"markdown","source":"## 3. Training SoundStream","metadata":{}},{"cell_type":"code","source":"soundstream = MusicLMSoundStream()\nsoundstream_trainer = SoundStreamTrainer(\n    soundstream,\n    **SOUNDSTREAM_TRAINER_KWARGS\n)\n\nsoundstream_trainer.train()\n\nsoundstream_trainer.save(soundstream_ckpt)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.257999Z","iopub.status.idle":"2023-10-27T14:05:13.258787Z","shell.execute_reply.started":"2023-10-27T14:05:13.258501Z","shell.execute_reply":"2023-10-27T14:05:13.258523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Training conditioning embeddings","metadata":{}},{"cell_type":"markdown","source":"Defining the MuLaN Embed Quantizer and Hubert K-means Embedder","metadata":{}},{"cell_type":"code","source":"quantizer = MuLaNEmbedQuantizer(\n    mulan=mulan,                         \n    **MULAN_QUANTIZER_KWARGS\n)\n\nwav2vec = HubertWithKmeans(\n    **HUBERT_KWARGS\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.260844Z","iopub.status.idle":"2023-10-27T14:05:13.261469Z","shell.execute_reply.started":"2023-10-27T14:05:13.261261Z","shell.execute_reply":"2023-10-27T14:05:13.261281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Semantic Transformer","metadata":{}},{"cell_type":"code","source":"semantic_transformer = SemanticTransformer(\n   num_semantic_tokens=wav2vec.codebook_size,\n   **SEMANTIC_KWARGS \n).to(DEVICE)\n\nsemantic_trainer = SemanticTransformerTrainer(\n    wav2vec,\n    semantic_transformer,\n    audio_conditioner=quantizer,\n    **TRANSFORMER_TRAINER_KWARGS\n)\n\nsemantic_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.262521Z","iopub.status.idle":"2023-10-27T14:05:13.263103Z","shell.execute_reply.started":"2023-10-27T14:05:13.262911Z","shell.execute_reply":"2023-10-27T14:05:13.262932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Coarse Transformer","metadata":{}},{"cell_type":"code","source":"soundstream = MusicLMSoundStream()\n\nsoundstream.load(soundstream_ckpt)\n\ncoarse_transformer = CoarseTransformer(\n    num_semantic_tokens=wav2vec.codebook_size,\n    **COARSE_KWARGS\n).to(DEVICE)\n\ncoarse_trainer = CoarseTransformerTrainer(\n    wav2vec,\n    semantic_transformer,\n    codec=soundstream,\n    audio_conditioner=quantizer,\n    **TRANSFORMER_TRAINER_KWARGS\n)\n\ncoarse_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.264153Z","iopub.status.idle":"2023-10-27T14:05:13.264748Z","shell.execute_reply.started":"2023-10-27T14:05:13.264544Z","shell.execute_reply":"2023-10-27T14:05:13.264577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Fine Transformer","metadata":{}},{"cell_type":"code","source":"soundstream = MusicLMSoundStream()\n\nsoundstream.load(soundstream_ckpt)\n\nfine_transformer = FineTransformer(\n    codebook_size=wav2vec.codebook_size,\n    **FINE_KWARGS\n).to(DEVICE)\n\nfine_trainer = FineTransformerTrainer(\n    wav2vec,\n    semantic_transformer,\n    codec=soundstream\n    audio_conditioner=quantizer,\n    **TRANSFORMER_TRAINER_KWARGS\n)\n\nfine_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.265788Z","iopub.status.idle":"2023-10-27T14:05:13.266359Z","shell.execute_reply.started":"2023-10-27T14:05:13.266160Z","shell.execute_reply":"2023-10-27T14:05:13.266179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Combining AudioLM and MusicLM","metadata":{}},{"cell_type":"code","source":"audio_lm = AudioLM(\n    wav2vec=wav2vec,\n    codec=soundstream,\n    semantic_transformer=semantic_transformer,\n    coarse_transformer=coarse_transformer,\n    fine_transformer=fine_transformer   \n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.267406Z","iopub.status.idle":"2023-10-27T14:05:13.268195Z","shell.execute_reply.started":"2023-10-27T14:05:13.267883Z","shell.execute_reply":"2023-10-27T14:05:13.267914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"music_lm = MusicLM(\n    audio_lm=audio_lm,\n    mulan_embed_quantizer=quantizer\n)\n\nmusic = music_lm('soul', num_samples=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.269473Z","iopub.status.idle":"2023-10-27T14:05:13.269919Z","shell.execute_reply.started":"2023-10-27T14:05:13.269723Z","shell.execute_reply":"2023-10-27T14:05:13.269743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(music, 'generated_music.pt')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.271755Z","iopub.status.idle":"2023-10-27T14:05:13.273254Z","shell.execute_reply.started":"2023-10-27T14:05:13.272832Z","shell.execute_reply":"2023-10-27T14:05:13.272874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_path = \"out.wav\"\nsample_rate = 44100\ntorchaudio.save(output_path, music.cpu(), sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:05:13.275225Z","iopub.status.idle":"2023-10-27T14:05:13.275900Z","shell.execute_reply.started":"2023-10-27T14:05:13.275581Z","shell.execute_reply":"2023-10-27T14:05:13.275612Z"},"trusted":true},"execution_count":null,"outputs":[]}]}